[{"path":[]},{"path":"https://rstudio.github.io/promises/dev/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://rstudio.github.io/promises/dev/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://rstudio.github.io/promises/dev/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://rstudio.github.io/promises/dev/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://rstudio.github.io/promises/dev/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement codeofconduct@posit.co. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://rstudio.github.io/promises/dev/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://rstudio.github.io/promises/dev/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://rstudio.github.io/promises/dev/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://rstudio.github.io/promises/dev/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://rstudio.github.io/promises/dev/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://rstudio.github.io/promises/dev/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://rstudio.github.io/promises/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 promises authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_01_motivation.html","id":"what-are-promises-good-for","dir":"Articles","previous_headings":"","what":"What are promises good for?","title":"Why use promises?","text":"Promises work well Shiny application particular operation, especially calculation, takes long time (measured seconds even minutes). Without promises, operations block current user’s session proceeding, also block requests made R process, matter trivial. Even loading small CSS file, nearly instantaneous, can delayed many seconds another user’s Shiny session busy crunching hundreds gigabytes data querying particularly slow backend database. promises, can convert long-running operations asynchronous, frees R process work. Shiny applications, potential greatly increase scalability R process (depending slow operations first place, resources make use ). use promises Shiny app long-running operations, want serve multiple users simultaneously.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_01_motivation.html","id":"what-arent-promises-good-for","dir":"Articles","previous_headings":"","what":"What aren’t promises good for?","title":"Why use promises?","text":"promises can make huge difference scalability Shiny app, make relatively little difference latency single session. say, Shiny application slow single user hitting , converting use promises unlikely make perform faster (fact may slightly slow ). Promises just help prevent sessions slowed one session’s computations. (exception Shiny app several distinct long computations don’t depend much —use asynchronous programming exploit little parallelism. think less common use async programming, R already good tools designed specifically data parallelism.) DON’T use promises improve performance Shiny apps single user. Next: informal intro async programming","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"async-programming-in-r","dir":"Articles","previous_headings":"","what":"Async programming in R","title":"Working with promises in R","text":"Integrating async programming capabilities R involves two types tasks: Invoking: Getting expensive operations happen either different thread, (likely) different process, leaving main R thread/process free continue work. Generally, expensive operation either produce result value (e.g. data frame), cause side effect (e.g. write database). Handling: operation completes fails, notify main R thread/process may make use resulting value error logic. Handling logic may choose perform side effects like logging persisting, transform value/error downstream processing. vision R async programming, several different ways invoking expensive operations asynchronously, different tradeoffs, depending type task trying execute. go detail later, just give idea, just different strategies use invoke code asynchronously: Run current process, different thread. (strategy impossible R code, can run C/C++ code different thread, even R process.) Launch separate R process pass R code evaluate. Fork R process run code child process. (Doesn’t work Windows.) Farm code pre-allocated cluster R processes, either machine distributed across network. Regardless approach choose, API handling result identical. ’s centered around abstraction come know well: promise.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"promises-the-central-abstraction-of-async-programming","dir":"Articles","previous_headings":"","what":"Promises: the central abstraction of async programming","title":"Working with promises in R","text":"Terminology note: Advanced R users (users least read Advanced R) may familiar term “promises” already: R, unevaluated function arguments technically called promises. types promises nothing asynchronous programming, things call “promises” document nothing , try forget exist time . Sorry confusion. promise object represents eventual result specific asynchronous operation. Whenever launch async task, get promise object back. promise lets know: task completes (ever) Whether task completed successfully failed success, result value failure, error regular, synchronous function call generally looks like : asynchronous function call (uses mirai package) look instead like: regular function call returns data frame, async call returns promise, definitely data frame. ask promise many rows , names columns. run dplyr operations , turn data.table. might guess call function method promise extract value, like value(promise) promise$value(). isn’t promises work. Instead, everything based function called .","code":"value <- read.csv(\"http://example.com/data/data.csv\") promise <- as.promise(mirai(read.csv(\"http://example.com/data/data.csv\")))"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"accessing-results-with-then","dir":"Articles","previous_headings":"","what":"Accessing results with then","title":"Working with promises in R","text":"promises::function ultimately makes promise objects useful. used register success failure handlers promise. signature looks like: promise terminology, “fulfilled” (equivalently, “resolved”) means success “rejected” means failure. can pass functions single arguments onFulfilled onRejected notified promise succeeds fails. (promise already fulfilled resolved time called, don’t worry—appropriate callback still called. ’s never late call promise.) promise library guarantees one onFulfilled onRejected called, never . callback never invoked . possible, though, neither callback ever called, .e. async operation never completes. (analogous calling regular function never returns.) now, focus fulfillment, come back rejection Error Handling section . following example shows simple example printing success message value. code looks ugly , don’t worry — ’ll rarely write promise code looks like . go, ’ll introduce several types syntactic sugar make working promises pleasant. start , can use magrittr pipe operator, gives us pretty marginal benefit right now pay dividends shortly: Note call () always returns immediately, without invoking callback function. callback function invoked sometime future—soon, hours, depending mostly long takes async operation complete.","code":"then(promise, onFulfilled = NULL, onRejected = NULL) then(promise,   function(value) {     cat(\"The operation completed!\\n\")     print(value)   }) promise %>%   then(function(value) {     cat(\"The operation completed!\\n\")     print(value)   })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"using-formulas","dir":"Articles","previous_headings":"","what":"Using formulas","title":"Working with promises in R","text":"don’t use anonymous functions callbacks; can use named functions well. promise %>% (print) works, just want print value. don’t named function want, though, still alternative using anonymous functions, can little verbose: can use formulas save keystrokes. use purrr’s “lambda formula” style; ’re familiar purrr, now just know can access value (error) using . variable name. (Yes, can entire blocks code formulas!)","code":"promise %>%   then(~{     cat(\"The operation completed!\")     print(.)   })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"using-pipes","dir":"Articles","previous_headings":"","what":"Using pipes","title":"Working with promises in R","text":"can take syntactic sugar step using promise pipe, promise-aware version %>% (magrittr pipe operator). promise pipe looks like %...>% performs tricks %>%, adds functionality . following two blocks code equivalent: (Note %...>% operator supports onFulfilled part (), ’s useful handling errors; ’s separate %...!% operator . ’ll cover section Error Handling.) Like magrittr’s pipe, promise pipe lets chain together operations using variety syntaxes. can use code blocks, can come handy multiple lines code execute don’t necessarily match pipe paradigm: can use anonymous functions (must wrap parentheses), helps prefer give promise result object explicit name (case, df):","code":"# Without promise pipe promise %>%   then(~{     filter(., state == \"NY\")   })  # Using promise pipe promise %...>%   filter(state == \"NY\") promise %...>% {   filter(., state == \"NY\") } promise %...>% (function(df) {   filter(df, state == \"NY\") })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"promise-chaining","dir":"Articles","previous_headings":"","what":"Promise chaining","title":"Working with promises in R","text":"function important function beyond registering callbacks. also returns promise—promise takes argument, new, distinct promise. new promise gets fulfilled input promise resolved callback registered run; return value callback used fulfill new promise. example: case, promise fulfilled data frame, promise2 fulfilled number rows data frame. uses promises input output, can chain multiple calls together directly: , equivalently: , third way: Evaluating expression results promise eventually resolve filtered, summarized, ordered data.","code":"promise2 <- promise %>%   then(nrow) promise %>%   then(filter(year == 2006)) %>%   then(group_by(state)) %>%   then(summarise(pop = sum(population))) %>%   then(arrange(desc(pop))) promise %...>%   filter(year == 2006) %...>%   group_by(state) %...>%   summarise(pop = sum(population)) %...>%   arrange(desc(pop)) promise %...>% (function(df) {   df %>%     filter(year == 2006) %>%     group_by(state) %>%     summarise(pop = sum(population)) %>%     arrange(desc(pop)) })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"tee-operator","dir":"Articles","previous_headings":"","what":"Tee operator","title":"Working with promises in R","text":"working promise pipelines, may sometimes useful stage performs action modify value presented downstream stages. example, may want log number rows data frame diagnostic purposes: correct, print(nrow(.)) stage print desired value, pass return value print(nrow(.)), just invisible(nrow(.)), next stage. synchronous code, magrittr offers %T>% (pronounced “tee”) operator, operates like regular %>% except , executing right-hand side, returns left-hand side value. Similarly, asynchronous code, can use %...T>% operator, like %...>% except execution resolves using input promise. difference corrected code operator immediately preceding print(nrow(.)) changed %...>% %...T>%.","code":"# Incorrect! promise %...>%   filter(year == 2006) %...>%   print(nrow(.)) %...>%   group_by(state) %...>%   summarise(pop = sum(population)) %...>%   arrange(desc(pop)) # Correct. promise %...>%   filter(year == 2006) %...T>%   print(nrow(.)) %...>%   group_by(state) %...>%   summarise(pop = sum(population)) %...>%   arrange(desc(pop))"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"error-handling","dir":"Articles","previous_headings":"","what":"Error handling","title":"Working with promises in R","text":"Many scripts Shiny apps use promises contain explicit error handling code , just like scripts Shiny apps don’t contain tryCatch try calls handle errors synchronous code. need handle errors, promises robust flexible mechanism .","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"catching-errors-with-onrejected","dir":"Articles","previous_headings":"Error handling","what":"Catching errors with onRejected","title":"Working with promises in R","text":"lowest level error handling built function. review, function takes input promise, two callbacks: onFulfilled onRejected; returns new promise output. operation behind input promise succeeds, onFulfilled callback (provided) invoked. input promise’s operation fails, onRejected (provided) invoked error object. code , can see success failure promise1 determine two callbacks invoked. output promise, promise2? know happens promise1 succeeds onFulfilled callback returns normally: promise2 resolved return value onFulfilled (return value promise, promise2 whatever promise ). happens promise1 rejected; automatically mean promise2 rejected well? answer , promise2 automatically rejected promise1 rejected. rejection promise1 causes onRejected called, , onFulfilled onRejected treated identically. Whichever callback invoked, invocation callback succeeds (returns either regular value, , promise ultimately resolves successfully) output promise resolved/succeed. invocation callback fails (either throws error, returns promise ultimately rejects) output promise rejected/fail. think , behavior makes sense; just like tryCatch, ’ve caught error, doesn’t continue propagate, unless go way re-throwing using stop(err). equivalent (synchronous) code: , operation performed asynchronously: synchronous case, error operation() result error logged warning, 0 assigned value. asynchronous case, warning log messages happen value 0 used resolve promise. cases, error caught, dealt , turned non-error.","code":"promise2 <- promise1 %>%   then(     onFulfilled = function(value) {       # Getting here means promise1 succeeded     },     onRejected = function(err) {       # Getting here means promise1 failed     }   ) value <- tryCatch(   somepkg::operation(),   error = function(err) {     warning(\"An error occurred: \", err)     warning(\"Using default value of 0 instead\")     0   } ) promise <- mirai(somepkg::operation()) %>%   then(onRejected = function(err) {     warning(\"An error occurred: \", err)     warning(\"Using default value of 0 instead\")     0   }"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"default-onrejected-behavior","dir":"Articles","previous_headings":"Error handling","what":"Default onRejected behavior","title":"Working with promises in R","text":"many examples , called onFulfilled onRejected. behavior input promise rejected error, caller provided explicit onRejected callback? Well, default version onRejected. ’s empty onRejected = function(err) { }, might think. Even though function code body, still returns normally, thus cause errors caught swallowed. ’s behavior want; code , want failure promise1 cause promise2 rejected know something went wrong. default callback actually looks like: onRejected = stop, meaning, nothing raise error, pushing responsibility error handling downstream. (Incidentally, ’s valid call onRejected onFulfilled, default version onFulfilled empty function either; instead, ’s onFulfilled = identity, input promise’s return value can passed output promise.)","code":"promise2 <- promise1 %>%   then(head) %>%   then(print)"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"syntactic-sugar-for-onrejected","dir":"Articles","previous_headings":"Error handling","what":"Syntactic sugar for onRejected","title":"Working with promises in R","text":"syntactic sugar offered non-error cases, available error handling code well. can use formulas onRejected: ’s error handling pipe operator %...!%, works similar %...>% binds (onRejected) instead (onFulfilled): ’s also catch() function just shorthand (onRejected). saves little typing, importantly, easier read:","code":"mirai(somepkg::operation()) %>%   then(onRejected = ~warning(.)) mirai(somepkg::operation()) %...!%   warning() mirai(somepkg::operation()) %>%   catch(warning)"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"error-tee","dir":"Articles","previous_headings":"Error handling","what":"Error tee","title":"Working with promises in R","text":"’s fairly common want something error without stopping propagating (logging), couple additional shorthands without explicitly call stop(err). example: print error, also eat . print error without eating , ’d : ’s fair amount boilerplate. Instead, can either add tee = TRUE catch call, equivalently, use %...T!% operator. two lines equivalent , previous code chunk:","code":"promise %...!% print() promise %...!% function(err) {   print(err)   stop(err) } promise %>% catch(print, tee = TRUE)  promise %...T!% print()"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_03_overview.html","id":"cleaning-up-with-finally","dir":"Articles","previous_headings":"","what":"Cleaning up with finally","title":"Working with promises in R","text":"synchronous programming, use eithertryCatch(expr, finally = ...) .exit(...) perform tasks (usually relating freeing resources reverting temporary changes) regardless whether main logic succeeds fails (throws error). programming promises, can use finally function . finally function similar takes single callback executes success failure, return value ignored. example, need temp file duration pipeline. finally makes sure temp file deleted operation done, regardless whether succeeded failed. Next: Launching tasks","code":"file_path <- tempfile(fileext = \".png\") png_bytes_promise <-   mirai(     {       png(file_path)       plot(cars)       dev.off()       file_path     },     file_path = file_path   ) %...>%   brio::read_file_raw() %>%   finally(~unlink(file_path))"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_04_mirai.html","id":"how-mirai-works","dir":"Articles","previous_headings":"","what":"How mirai works","title":"Launching tasks with mirai","text":"main API mirai provides couldn’t simpler. call mirai() pass code want executed asynchronously: object ’s returned mirai, intents purposes promise object1, eventually resolve return value code block (.e. last expression) error code complete executing successfully. important thing matter long expensive operation takes, lines execute almost instantly, operation continues background. know R single-threaded, mirai accomplish ? answer: utilizing another R process. mirai delegates execution expensive operation totally different R process, original R process can move .","code":"m <- mirai({   # expensive operations go here...   df <- download_lots_of_data()   fit_model(df) })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_04_mirai.html","id":"choosing-a-launch-method","dir":"Articles","previous_headings":"","what":"Choosing a launch method","title":"Launching tasks with mirai","text":"mirai, daemons() function used set launch background R processes (daemons). background processes used/recycled life originating R process. mirai launched background R processes busy executing, new mirai queued one background processes frees . launch n processes locally, just need call daemons(n), supplying value n. need determine n , typically one less number processor cores machine, leave one main R process. reason don’t automatically detect may also running tasks machine, take account supplying value n. daemons() arguments url remote setting launching remote daemons network distributed computing. learn , see mirai::daemons() reference docs well daemons sections mirai reference vignette. don’t set daemons() session, mirai() call launch new local R process solely purpose performing evaluation. Whilst may desirable certain circumstances, rarely going case Shiny. limit total number processes spawned one time. Shiny app many simultaneous users, lead excessive number processes created, overwhelming system.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_04_mirai.html","id":"caveats-and-limitations","dir":"Articles","previous_headings":"","what":"Caveats and limitations","title":"Launching tasks with mirai","text":"abstractions mirai presents simple consistent, although may take time get used . Please read entire section carefully proceeding.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_04_mirai.html","id":"globals-providing-input-to-mirai-code-chunks","dir":"Articles","previous_headings":"Caveats and limitations","what":"Globals: Providing input to mirai code chunks","title":"Launching tasks with mirai","text":"mirai code chunks need reference data original process, e.g. data fitted, URLs requested, file paths read . evaluation happens another process, won’t available code chunk default. objects need passed ... argument mirai() call. serialized sent process along code executed. objects include functions defined session package. example: many variables pass , mirai offer convenience feature pass environment instead individual ... pairs. call look like instead: passes calling environment, includes download_data function well url. Care taken using feature also pass anything else happens environment. safer use mirai called inside another function, environment() consist variables passed arguments function, created locally within .","code":"download_data <- function(url) {   file <- tempfile()   download.file(url, file, \"libcurl\")   file }  url <- \"http://example.com/data.csv\"  m <- mirai(   {     file <- download_data(url)     read.csv(file)   },   download_data = download_data,   url = url ) m <- mirai(   {     file <- download_data(url)     read.csv(file)   },   environment() )"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_04_mirai.html","id":"package-loading","dir":"Articles","previous_headings":"Caveats and limitations","what":"Package loading","title":"Launching tasks with mirai","text":"Besides variables, package functions need declared full namespace can found process. example, using dplyr::mutate() instead just mutate(), even dplyr package loaded main session, process packages loaded default. Alternatively, make call load package inside mirai code chunk, example adding library(dplyr). Sometimes may convenient option, especially infix operators. example magrittr pipe %>%, requires library(magrittr) load package beforehand.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_04_mirai.html","id":"custom-data-types","dir":"Articles","previous_headings":"Caveats and limitations","what":"Custom Data Types","title":"Launching tasks with mirai","text":"Certain objects implemented low level, using one R’s native vector types, represented R external pointer. example Arrow table. possible serialize R’s native rds format. Instead provide serialization deserialization methods. mirai offers seamless solution working data types, integrating custom serialization deserialization methods R’s native serialization don’t need manually handle instance objects moving across processes. require one-configuration step set daemons, may read mirai serialization vignette.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_04_mirai.html","id":"native-resources","dir":"Articles","previous_headings":"Caveats and limitations","what":"Native resources","title":"Launching tasks with mirai","text":"Mirai code blocks use resources database connections network sockets created parent process. Even seems work simple test, asking crashes worse sharing kinds resources across processes. Instead, make sure create, use, destroy resources entirely within scope mirai code block.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_04_mirai.html","id":"mutation","dir":"Articles","previous_headings":"Caveats and limitations","what":"Mutation","title":"Launching tasks with mirai","text":"Reference class objects (including R6 objects, S7 objects, data.table objects) environments among “native” R object types mutable, , can modified -place. Unless contain native resources (see previous section), ’s nothing wrong using mutable objects within mirai code blocks, even objects created parent process. However, note changes make objects visible parent process; mirai code operating copy object, original.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_04_mirai.html","id":"returning-values","dir":"Articles","previous_headings":"Caveats and limitations","what":"Returning values","title":"Launching tasks with mirai","text":"Mirai code blocks return value—’d lot less useful couldn’t! Like everywhere else R, return value determined last expression code block, unless return() explicitly called earlier. return value always copied back parent process. matters two reasons. First, return value large, copying process can take time — data must essentially serialized deserialized rds format, can take surprising amount time. case mirai blocks execute fairly quickly return huge amounts data, may better using async techniques . Second, objects refer native resources unlikely work direction either; just can’t use parent’s database connections child process, also child process return database connection parent use. Next: Using promises Shiny","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_05a_futures.html","id":"how-future-works","dir":"Articles","previous_headings":"","what":"How future works","title":"Launching tasks with future","text":"main API future provides couldn’t simpler. call future() pass code want executed asynchronously: object ’s returned future, intents purposes promise object1, eventually resolve return value code block (.e. last expression) error code complete executing successfully. important thing matter long expensive operation takes, lines execute almost instantly, operation continues background. know R single-threaded, future accomplish ? answer: utilizing another R process. future delegates execution expensive operation totally different R process, original R process can move .","code":"f <- future({   # expensive operations go here...   df <- download_lots_of_data()   fit_model(df) })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_05a_futures.html","id":"choosing-a-launch-method","dir":"Articles","previous_headings":"","what":"Choosing a launch method","title":"Launching tasks with future","text":"several different methods use launching R processes attaching existing R processes, method advantages, disadvantages, limitations, requirements. Rather prescribing single method, future package provides extensible mechanism lets , R user, decide method use. Call plan() function one following values (without quotes—function names, strings): multisession: Launches n background R processes machine (n number processor cores system, minus 1). background processes used/recycled life originating R process. future launched background R processes busy executing, new future queued one background processes free . multicore: new task executes forked child process. Forking generally much faster launching new process scratch, state original process available child process without go extra effort (see section Globals ). biggest limitation forking doesn’t work Windows operating systems, majority R users use. also dangerous edge cases style execution (Google “fork without exec” information), though popular frameworks like RServe OpenCPU rely heavily don’t seem suffer . future package also includes sequential method, executes synchronously therefore relevant purposes. Unfortunately, sequential default, hence explicitly calling plan() different method must. also cluster method, well separate future.batchtools package, distributed execution; may work promises, tested team described document. learn , see future::plan() reference docs well future overview.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_05a_futures.html","id":"caveats-and-limitations","dir":"Articles","previous_headings":"","what":"Caveats and limitations","title":"Launching tasks with future","text":"abstractions future presents simple, leaky. can’t make effective use future without understanding various strategies running R tasks asynchronously. Please read entire section carefully proceeding.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_05a_futures.html","id":"globals-providing-input-to-future-code-chunks","dir":"Articles","previous_headings":"Caveats and limitations","what":"Globals: Providing input to future code chunks","title":"Launching tasks with future","text":"future code chunks need reference data original process, e.g. data fitted, URLs requested, file paths read . future package goes lengths try make process seamless , inspecting code chunk predicting variables original process copied child process. testing works fairly reliably multicore, somewhat less reliably multisession. Multisession also distinct disadvantage identified variables must physically (though automatically) copied main child processes, can extremely time-consuming data large. (multicore strategy need , every forked process starts memory state parent time fork.) summary, ’s possible false positives (data copied doesn’t need ) false negatives (data available ’s needed) occur. Therefore, simplest cases, suggest suppressing future’s automated variable copying instead manually specifying relevant variables, using future() function’s globals parameter. can pass character vector (globals = c(\"var_a\", \"var_b\")) named list (globals = c(data = mtcars, iterations = n)). One final note globals: safety measure, future() error size data shuttled processes exceeds 500MB. true whether variables copy identified automatic detection, explicitly via globals parameter; ’s even true ’re using multicore strategy, copies actually made. data potentially large, ’ll want increase limit setting future.globals.maxSize option suitably high number bytes, e.g. options(future.globals.maxSize=1e9) billion bytes.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_05a_futures.html","id":"package-loading","dir":"Articles","previous_headings":"Caveats and limitations","what":"Package loading","title":"Launching tasks with future","text":"Besides variables, future() also tries automatically infer R packages need loaded child process. automatic detection sufficient, can use future() function’s packages parameter pass character vector package names, e.g. packages = c(\"dplyr\", \"ggplot2\"). , especially important multisession, multicore inherit attached packages parent process.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_05a_futures.html","id":"native-resources","dir":"Articles","previous_headings":"Caveats and limitations","what":"Native resources","title":"Launching tasks with future","text":"Future code blocks use resources database connections network sockets created parent process. true regardless future implementation use! Even seems work simple test, asking crashes worse sharing kinds resources across processes. Instead, make sure create, use, destroy resources entirely within scope future code block.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_05a_futures.html","id":"mutation","dir":"Articles","previous_headings":"Caveats and limitations","what":"Mutation","title":"Launching tasks with future","text":"Reference class objects (including R6 objects data.table objects) environments among “native” R object types mutable, , can modified -place. Unless contain native resources (see previous section), ’s nothing wrong using mutable objects within future code blocks, even objects created parent process. However, note changes make objects visible parent process; future code operating copy object, original.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_05a_futures.html","id":"returning-values","dir":"Articles","previous_headings":"Caveats and limitations","what":"Returning values","title":"Launching tasks with future","text":"Future code blocks can return value—’d lot less useful couldn’t! Like everywhere else R, return value determined last expression code block, unless return() explicitly called earlier. Regardless future method, return value copied back parent process. matters two reasons. First, return value large, copying process can take time—data must essentially serialized deserialized rds format, can take surprising amount time. case future blocks execute fairly quickly return huge amounts data, may better using future/async techniques . Second, objects refer native resources unlikely work direction either; just can’t use parent’s database connections child process, also child process return database connection parent use. Next: Advanced future promises usage Using promises Shiny","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_05b_future_promise.html","id":"the-problem-with-futurepromise","dir":"Articles","previous_headings":"","what":"The problem with future()+promise()","title":"Advanced future and promises usage","text":"ideal situation, number available future workers (future::nbrOfFreeWorkers()) always number future::future() jobs. However, future job attempted number free workers 0, future block current R session one becomes available. concrete example, let’s imagine scenario, seven plumber requests received time two future workers available. Also, let’s assume plumber route(s) serving first 6 requests use future::future() take ~10s compute slow_calc(): Let’s also assume plumber route serving last request use form future promises takes almost time compute. figure depicts overall timeline execution 7 requests conditions ’ve outlined . Note y-axis ordered first request coming (/slow/1) last request (/fast/7).  Note R wait 20s processing 7th request (shown green). big improvement using future+promises (case, R wait 60s processing). However, since two future workers available R still wait longer necessary process last request main R session must wait future worker become available. video animates behavior:","code":"#* @get /slow/<k> function() {   future::future({     slow_calc()   }) } #* @get /fast/<k> function() {   fast_calc() }"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_05b_future_promise.html","id":"the-solution-future_promise","dir":"Articles","previous_headings":"","what":"The solution: future_promise()","title":"Advanced future and promises usage","text":"advantage using future_promise() future::future() even aren’t future workers available, future scheduled done workers become available via promises. words, future_promise() ensures main R thread isn’t blocked future job requested can’t immediately perform work (.e., number jobs exceeds number workers). Continuing example , can swap calls future::future() future_promise(). change future_promise(), note /fast/7 route now wait future work finish processing. Therefore, plumber can complete last requests almost immediately:  vertical gray bars figure represent timepoints main R session actually busy. Outside gray areas, R session free things, example, executing promises , generally, non-future work. video animates behavior: Next: Using promises Shiny","code":"#* @get /slow/<k> function() {   promises::future_promise({     slow_calc()   }) }"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_06_shiny.html","id":"adding-prerequisites","dir":"Articles","previous_headings":"","what":"Adding prerequisites","title":"Using promises with Shiny","text":"easiest part adding library(promises), library(mirai), daemons(6) top app. promises library necessary %...>% operator. may also want use promise utility functions like promise_all promise_race. mirai library needed mirai() function call launch asynchronous tasks. daemons(6) directive mirai package, telling tasks actually executed. See article mirai details.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_06_shiny.html","id":"identifying-slow-operations","dir":"Articles","previous_headings":"","what":"Identifying slow operations","title":"Using promises with Shiny","text":"find areas code good candidates mirai/promise treatment, let’s start obvious: identifying code making app slow. may assume ’s plotting code ’s slow, ’s actually database queries; vice versa. ’s one thing veteran programmers can agree , ’s human intuition surprisingly unreliable tool spotting performance problems. recommendation use profvis profiler, designed work Shiny (see Example 3 profvis documentation). can use profvis help focus time actually spent app. Note: writing, profvis doesn’t work particularly well diagnosing performance problems parts code ’ve already made asynchronous. particular, haven’t done work help profile code executes mirai, mechanism use hide “irrelevant” parts stack trace doesn’t work well promises. ripe areas future development. Async programming works well can identify just “hotspots” app lots time spent. works much less well app slow generalized, diffuse slowness every aspect app, one operation takes much time adds lot. mirai need introduce app, fixed communication overhead incur. bang---buck, want launch small number mirai per session move lot waited-code one.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_06_shiny.html","id":"converting-a-slow-operation-into-a-mirai","dir":"Articles","previous_headings":"","what":"Converting a slow operation into a mirai","title":"Using promises with Shiny","text":"Now ’ve found hotspots want make asynchronous, let’s talk actual work converting mirai. Conceptually, mirai works like : seems incredibly simple. ’s actually happening mirai runs totally separate child R process, result collected returned main R process: fact mirai code block executes separate process means take special care deal number practical issues. objects required code block must passed along part mirai() function call; certain objects may require custom serialization set , objects safely used across process boundaries. , see article mirai details.","code":"mirai({   # Expensive code goes here }) %...>% (function(result) {   # Code to handle result of expensive code goes here }) # Code here runs in process A mirai({   # Code here runs in (child) process B }) %...>% (function(result) {   # Code here runs in process A })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_06_shiny.html","id":"shiny-specific-caveats-and-limitations","dir":"Articles","previous_headings":"Converting a slow operation into a mirai","what":"Shiny-specific caveats and limitations","title":"Using promises with Shiny","text":"addition constraints mirai faces, additional one Shiny: reactive values reactive expressions read within mirai. Whenever reactive values/expressions read, side effects carried hood currently executing observer reactive expression can notified reactive value/expression becomes invalidated. reactive value/expression created one process, read another process, way readers notified invalidation. code, example, work: Even though r1() called inside r2 reactive expression, fact ’s also mirai means call fail. Instead, must read reactive values/expressions need advance launching mirai: However, ’s perfectly fine read reactive values/expressions inside promise handler. Handlers run original process, child process, reactive operations allowed.","code":"function(input, output, session) {   r1 <- reactive({ ... })    r2 <- reactive({     mirai(       {         r1() # Will error--don't do this!       },       r1 = r1     )   }) } function(input, output, session) {   r1 <- reactive({ ... })    r2 <- reactive({     val <- r1()     mirai(       {         val # No problem!       },       val = val     )   }) } function(input, output, session) {   r1 <- reactive({ ... })    r2 <- reactive({     mirai({ ... }) %...>%       rbind(r1()) # OK!   }) }"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_06_shiny.html","id":"integrating-promises-with-shiny","dir":"Articles","previous_headings":"","what":"Integrating promises with Shiny","title":"Using promises with Shiny","text":"Generally, ’ll using promises Shiny within outputs, reactive expressions, observers. ’ve tried integrate promises constructs natural way possible.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_06_shiny.html","id":"outputs","dir":"Articles","previous_headings":"Integrating promises with Shiny","what":"Outputs","title":"Using promises with Shiny","text":"outputs (renderXXX({ ... })) functions expect code block return value; example, renderText() expects character vector renderTable() expects data frame. render functions included within shiny package can now optionally given promise value instead. : become: , trading elegance efficiency: important thing keep mind promise (promise pipeline) must final expression code block. Shiny knows promises actually return hand control back.","code":"output$table <- renderTable({   read.csv(url) %>%     filter(date == input$date) }) output$table <- renderTable({   mirai(read.csv(url), url = url) %...>%     filter(date == input$date) }) output$table <- renderTable({   input_date <- input$date   mirai(     {       read.csv(url) %>% filter(date == input_date)     },     url = url,     input_date = input_date   ) })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_06_shiny.html","id":"render-functions-with-side-effects-renderprint-and-renderplot","dir":"Articles","previous_headings":"Integrating promises with Shiny > Outputs","what":"Render functions with side effects: renderPrint and renderPlot","title":"Using promises with Shiny","text":"render functions renderPrint() renderPlot() slightly different render functions, can affected side effects code block provide. renderPrint can print console, renderPlot can plot active R graphics device. promises, render functions can work similar way, caveat. hopefully understand now, mirai executes code separate R process, printing/plotting separate process won’t effect Shiny output original process. examples, , incorrect: Instead, printing plotting control returns back original process, via promise handler: , need careful make sure last expression code block promise/pipeline; way rendering logic can know whether logic completed, errors occurred (can displayed user).","code":"output$summary <- renderPrint({   mirai(     {       read.csv(url) %>%         summary() %>%         print()     },     url = url   ) })  output$plot <- renderPlot({   mirai(     {       df <- read.csv(url)       ggplot(df, aes(length, width)) + geom_point()     },     url = url   ) }) output$summary <- renderPrint({   mirai(read.csv(url), url = url) %...>%     summary() %...>%     print() })  output$plot <- renderPlot({   mirai(read.csv(url), url = url) %...>%   {     ggplot(., aes(length, width)) + geom_point()   } })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_06_shiny.html","id":"observers","dir":"Articles","previous_headings":"Integrating promises with Shiny","what":"Observers","title":"Using promises with Shiny","text":"Observers similar outputs: must make sure last expression code block promise/pipeline. Like outputs, observers need know whether ’re done running, errors occured (can log terminate user session). way communicate async user code returning promise. ’s synchronous example ’ll convert async. Clicking refresh_data action button causes data downloaded, saved disk cached.rds also used update reactive value data. async version: Note version, call data(df) inside mirai, cause update happen wrong process. Instead, use %...>% operator perform assignment back main process mirai resolves.","code":"data <- reactiveVal(readRDS(\"cached.rds\"))  function(input, output, session) {   observeEvent(input$refresh_data, {     df <- read.csv(url)     saveRDS(df, \"cached.rds\")     data(df)   }) } data <- reactiveVal(readRDS(\"cached.rds\"))  function(input, output, session) {   observeEvent(input$refresh_data, {     mirai(       {         df <- read.csv(url)         saveRDS(df, \"cached.rds\")         df       },       url = url     ) %...>%       data()   }) }"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_06_shiny.html","id":"reactive-expressions","dir":"Articles","previous_headings":"Integrating promises with Shiny","what":"Reactive expressions","title":"Using promises with Shiny","text":"Recall reactive expressions used calculate values, cached automatically invalidated one dependencies. Unlike outputs observers, reactive expressions can used reactive consumers. Asynchronous reactive expressions similar regular (synchronous) reactive expressions: instead “normal” value, return promise yield desired value; normal reactive cache normal value, async reactive cache promise. upshot defining async reactive expression, code block return promise promise pipeline, following rules reactive outputs. calling async reactive expression, call like function like regular reactive expression, treat value ’s returned like promise. now async:","code":"function(input, output, session) {   data <- eventReactive(input$refresh_data, {     read.csv(url)   })    filteredData <- reactive({     data() %>% filter(date == input$date)   })    output$table <- renderTable({     filteredData() %>% head(5)   }) } function(input, output, session) {   data <- eventReactive(input$refresh_data, {     mirai(read.csv(url), url = url)   })    filteredData <- reactive({     data() %...>% filter(date == input$date)   })    output$table <- renderTable({     filteredData() %...>% head(5)   }) }"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_06_shiny.html","id":"the-flush-cycle","dir":"Articles","previous_headings":"","what":"The flush cycle","title":"Using promises with Shiny","text":"past, Shiny’s reactive programming model operated using mostly traditional event loop model. Somewhere many levels beneath shiny::runApp() piece code looked bit like : call Shiny’s “flush cycle”. two important properties flush cycle. one four steps—receiving, updating, reacting, sending—can executing time. (Remember, R single threaded.) particular, ’s possible inputs updated outputs/observers running. important order avoid race conditions impossible defend . Many outputs may change result single input value received browser, none sent back client outputs ready. advantage smoother experience end-user cases. (Admittedly, controversy regarding property Shiny; app authors strongly prefer show outputs soon ready, least manual control behavior.) adding async support Shiny, aimed keep two properties intact. Imagine now flushReact(), line executes invalidated outputs/observers, returns promise combines async outputs/observers (.e. promise resolves async outputs/observers resolved). new, async-aware event loop conceptually like : resulting behavior matches synchronous version event loop, : inputs received browser pending async outputs/observers completed. Unlike synchronous version, separation enforced session level: Session async observers finished executing, prevents Session processing new input values, new input values Session B can handled immediately belong different session. , goal keeping input updates separate output/observer execution prevent race conditions, even pernicious debug understand async code involved. given session, outputs sent back client, outputs ready. doesn’t matter whether outputs question synchronous, asynchronous, combination; must complete execution can sent.","code":"while (TRUE) {   # Do nothing until a browser sends some data   input <- receiveInputFromBrowser()   # Use the received data to update reactive inputs   session$updateInput(input)   # Execute all invalidated outputs/observers   flushReact()   # After ALL outputs execute, send the results back   flushOutputs() } doEventLoop <- function() {   # Do nothing until a browser sends some data   input <- receiveInputFromBrowser()   # Use the received data to update reactive inputs   session$updateInput(input)   # Execute all invalidated outputs/observers   flushReact() %...>% {     # After ALL outputs execute, send the results back     flushOutputs()     # Continue the event loop     doEventLoop()   } }"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_07_combining.html","id":"gathering","dir":"Articles","previous_headings":"","what":"Gathering","title":"Combining promises","text":"common pattern combining promises gathering, two promises hand want use results computation. promise_all function designed . signature looks like : promise_all takes number promises named arguments, returns promise list containing named elements results promises. ’s example using promise_all combine results two async read.csv operations: example, value . within curly braces list whose elements b data frames. use rbind combine . .$ prefix bit inelegant, recommend use base R function , lets skip prefix. ’s example, : (Note since promise_all argument names variable names (= , b = b), original variables masked: inside block, now refers result promise , promise object . find confusing, can just choose different argument name, like promise_all(a_result = , …).) combination promise_all concise powerful way gather results multiple promises. promise_all also gives two options passing input promises. First, rather result list unnamed, can pass promises unnamed arguments: promise_all(, b) yield list(1, 2). Second, list promises already hand, can pass list single argument using promise_all(.list = x) (instead , say, using .call(promise_all, x)).","code":"promise_all(..., .list = NULL) library(promises) library(mirai)  a <- mirai(read.csv(\"a.csv\")) b <- mirai(read.csv(\"b.csv\"))  result <- promise_all(a = a, b = b) %...>% {   rbind(.$a, .$b) } library(promises) library(mirai)  a <- mirai(read.csv(\"a.csv\")) b <- mirai(read.csv(\"b.csv\"))  promise_all(a = a, b = b) %...>%   with({     rbind(a, b)   })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_07_combining.html","id":"nesting","dir":"Articles","previous_headings":"","what":"Nesting","title":"Combining promises","text":"Gathering easy convenient, sometimes flexible enough. example, use result promise decide whether launch second async task, whose result use combination result . (use anonymous functions mask names original promises–.e. inside first anonymous function, symbol now refers result promise .) nesting pattern effective flexible. main downside physical nesting source code; use pattern depth couple promises, code quite indented (programming jargon referred “pyramid doom”).","code":"library(promises) library(mirai)  a <- mirai(1)  a %...>% (function(a) {   b <- mirai(2)   b %...>% (function(b) {     a + b   }) })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_07_combining.html","id":"racing","dir":"Articles","previous_headings":"","what":"Racing","title":"Combining promises","text":"promise_race takes multiple promises returns new promise fulfilled first promise succeeds. example , first promise fulfilled 2 0.5 seconds. one input promises rejects succeed, returned promise rejected. Note promises currently support cancellation. losing promises attempt run completion even race ends.","code":"library(promises) library(mirai)  a <- mirai({ Sys.sleep(1); 1 }) b <- mirai({ Sys.sleep(0.5); 2 })  first <- promise_race(a, b)"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_07_combining.html","id":"mapping","dir":"Articles","previous_headings":"","what":"Mapping","title":"Combining promises","text":"Use promise_map run async operation element list vector, collect results list. ’s similar lapply purrr::map, except function apply can return promise, return value also promise. example , iterate named vector package names. package name, launch async task download package’s description file CRAN pick last published date. resulting output looks like : promise_map works serially; time calls given function element list/vector, wait returned promise resolve proceeding next element. Furthermore, error rejected promise cause entire promise_map operation reject. want behavior ’s similar promise_map async operations occur parallel, can achieve combination regular purrr::map promise_all:","code":"library(promises) library(mirai)  get_pub_date <- function(pkg) {   desc_url <- paste0(\"https://cran.r-project.org/web/packages/\", pkg, \"/DESCRIPTION\")   mirai(     {       r <- read.dcf(url(desc_url))[, \"Date/Publication\"]       unname(r)     },     desc_url = desc_url   ) }  packages <- setNames(, c(\"ggplot2\", \"dplyr\", \"knitr\"))  pkg_dates <- promise_map(packages, get_pub_date)  pkg_dates %...>% print() $ggplot2 [1] \"2025-04-09 09:40:10 UTC\"  $dplyr [1] \"2023-11-17 16:50:02 UTC\"  $knitr [1] \"2025-03-16 09:20:02 UTC\" pkg_dates <- purrr::map(packages, get_pub_date) %>%   promise_all(.list = .)  pkg_dates %...>% print()"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_07_combining.html","id":"reducing","dir":"Articles","previous_headings":"","what":"Reducing","title":"Combining promises","text":"Use promise_reduce list want run async operation elements, serially (.e. one async operation runs time). can helpful ’re searching elements using async operation want terminate early search succeeds. signature promise_reduce follows: ’ve worked base::Reduce() purr:::reduce(), seem reasonably familiar: x vector list; func function takes two arguments, accumulated value “next” value; init default accumulated value. main difference promise_reduce purrr:::reduce promise_reduce, func can return promise. , promise_reduce wait resolve updating accumulated value invoking func next element. result returned promise_reduce promise resolves ultimate accumulated value. following example loops partial list CRAN mirrors, returning first one passes whatever check http::http_error performs.","code":"promise_reduce(x, func, init = NULL) library(promises) library(mirai)  cran_mirrors <- c(   \"https://cloud.r-project.org\",   \"https://cran.usthb.dz\",   \"https://cran.csiro.au\",   \"https://cran.wu.ac.at\" )  promise_reduce(   cran_mirrors,   function(result, mirror) {     if (!is.null(result)) {       result     } else {       mirai(         {           # Test the URL; return the URL on success, or NULL on failure           if (!httr::http_error(mirror)) mirror         },         mirror = mirror       )     }   },   .init = NULL ) %...>%   print()"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"Case study: converting a Shiny app to async","text":"web service increases popularity, number rogue scripts abuse apparent reason. —Cheng’s Law Can’t Nice Things first noticed 2011, -new RStudio IDE starting gather steam. dashboard tracked often RStudio downloaded, numbers generally tracking smoothly upward. every months, ’d huge spikes download counts, ten times greater normal—invariably, ’d find unexpected increase tracked one two IP addresses. hours days ’d inundated thousands downloads per hour, just suddenly, ’d cease. didn’t know happening , still don’t know today. world’s least competent denial--service attempt? someone write download script accidental (TRUE) around ? application let us examine downloads CRAN kind behavior. given day CRAN, ’ll see top downloaders ’re behaving.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"our-source-data","dir":"Articles","previous_headings":"","what":"Our source data","title":"Case study: converting a Shiny app to async","text":"RStudio maintains popular 0-Cloud CRAN mirror, log files generates freely available http://cran-logs.rstudio.com/. day separate gzipped CSV file, row single package download. privacy, IP addresses anonymized substituting day’s IP addresses unique integer IDs. first lines http://cran-logs.rstudio.com/2018/2018-05-26.csv.gz : Fortunately purposes, ’s need analyze logs high level figure days affected badly behaved download scripts. CRAN mirrors popular enough , according Cheng’s Law, plenty rogue scripts hitting every day year.","code":"\"date\",\"time\",\"size\",\"r_version\",\"r_arch\",\"r_os\",\"package\",\"version\",\"country\",\"ip_id\" \"2018-05-26\",\"20:42:23\",450377,\"3.4.4\",\"x86_64\",\"linux-gnu\",\"lubridate\",\"1.7.4\",\"NL\",1 \"2018-05-26\",\"20:42:30\",484348,NA,NA,NA,\"homals\",\"0.9-7\",\"GB\",2 \"2018-05-26\",\"20:42:21\",98484,\"3.3.1\",\"x86_64\",\"darwin13.4.0\",\"miniUI\",\"0.1.1.1\",\"NL\",1 \"2018-05-26\",\"20:42:27\",518,\"3.4.4\",\"x86_64\",\"linux-gnu\",\"RCurl\",\"1.95-4.10\",\"US\",3"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"a-tour-of-the-app","dir":"Articles","previous_headings":"","what":"A tour of the app","title":"Case study: converting a Shiny app to async","text":"app built explore data, cranwhales, let us examine behavior top downloaders (“whales”) given day, varying levels detail. can view app live https://gallery.shinyapps.io/cranwhales/, download run code https://github.com/rstudio/cranwhales. app starts, “traffic” tab shows number package downloads per hour users vs. whales. screenshot, can see proportion files downloaded top six downloaders May 28, 2018. may look like huge fraction first, keep mind, talking six downloaders 52,815 total! “Biggest whales” tab simply shows prolific downloaders, number downloads performed. anonymized IP address assigned easier--remember name, can also see country code original IP address. “Whales hour” tab shows hourly download counts whale individually. screenshot, can see Netherlands’ relieved_snake downloaded extremely consistent rate whole day, American curly_capabara active business hours Eastern Standard Time. Still others, like colossal_chicken Hong Kong, busy day varying rates. “Detail View” perhaps illuminating information. lets view every download made given whale day question. x dimension time y dimension package downloaded, can see glance exactly many packages downloaded, various package downloads relate . case, relieved_snake downloaded 104 different packages, order, continuously, entire day. Others behave differently, like freezing_tapir, downloaded devtools–devtools–whole day, racking 19,180 downloads totalling 7.9 gigabytes one package alone! Sadly, app can’t tell us –can’t explain downloaders behaving way, can tell us street addresses can send ninjas black RStudio helicopters make stop.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"the-implementation","dir":"Articles","previous_headings":"","what":"The implementation","title":"Case study: converting a Shiny app to async","text":"Now ’ve seen app , let’s talk implemented, convert sync async.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"user-interface","dir":"Articles","previous_headings":"The implementation","what":"User interface","title":"Case study: converting a Shiny app to async","text":"user interface pretty typical shinydashboard. ’s important note UI part app entirely agnostic whether server written sync async style; port app async, won’t touch UI . two major pieces input need users: date examine (app lets us look one day time) many prolific downloaders look . ’ll put two controls dashboard sidebar. (set date two days ago default, ’s lag day ends logs published.) rest UI code just typical shinydashboard scaffolding, plus shinydashboard::valueBoxOutputs plotOutputs. trivial ’re hardly worth talking , ’ll include code completeness. Finally, ’s detailViewUI, Shiny module just contains (value boxes plots).","code":"dashboardSidebar(   dateInput(\"date\", \"Date\", value = Sys.Date() - 2),   numericInput(\"count\", \"Show top N downloaders:\", 6) ) dashboardBody(     fluidRow(       tabBox(width = 12,         tabPanel(\"All traffic\",           fluidRow(             valueBoxOutput(\"total_size\", width = 4),             valueBoxOutput(\"total_count\", width = 4),             valueBoxOutput(\"total_downloaders\", width = 4)           ),           plotOutput(\"all_hour\")         ),         tabPanel(\"Biggest whales\",           plotOutput(\"downloaders\", height = 500)         ),         tabPanel(\"Whales by hour\",           plotOutput(\"downloaders_hour\", height = 500)         ),         tabPanel(\"Detail view\",           detailViewUI(\"details\")         )       )     )   )"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"server-logic","dir":"Articles","previous_headings":"The implementation","what":"Server logic","title":"Case study: converting a Shiny app to async","text":"Based inputs outputs, ’ll write variety reactive expressions output renderers download, manipulate, visualize relevant log data. reactive expressions: data (eventReactive): Whenever input$date changes, data reactive downloads full log day http://cran-logs.rstudio.com, parses . whales (reactive): Reads data(), tallies number downloads performed unique IP, returns data frame top input$count prolific downloaders, along download counts. whale_downloads (reactive): Joins data() whales() data frames, return details cetacean downloads. whales reactive expression depends data, whale_downloads depends data whales. outputs app mostly either renderPlots populate ggplot2, shinydashboard::renderValueBoxes. rely one reactive expressions just described. won’t catalog , ’re individually interesting, look archetypes .","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"improving-performance-and-scalability","dir":"Articles","previous_headings":"","what":"Improving performance and scalability","title":"Case study: converting a Shiny app to async","text":"article specifically async, good time remind lots ways improve performance Shiny app. Async just one tool toolbox, reaching hammer, take moment consider options: used profvis profile code determine ’s actually taking long? (Human intuition notoriously bad profiler!) Can perform calculations, summarizations, aggregations offline, Shiny app isn’t even running, save results .rds files read app? opportunities cache–, save results calculations use get request later? (See memoise, roll .) effectively leveraging reactive programming make sure reactives little work possible? deploying app, load balancing across multiple R processes /multiple servers? (Shiny Server Pro, RStudio Connect, ShinyApps.io) options generally useful using async techniques can dramatically speed performance app even single user using . obviously depends particulars app , lines precomputation caching logic can often lead 10X-100X better performance. Async, hand, generally doesn’t help make single session faster. Instead, helps single Shiny process support concurrent sessions without getting bogged . Async can essential tool way around performing expensive tasks (.e. taking multiple seconds) user waits. example, app analyzes user-specified Twitter profile may get many unique queries (assuming people specify Twitter handle) caching much help. applications invite users upload datasets won’t opportunity offline summarizing advance. need run apps like support lots concurrent users, async can huge help. sense, cranwhales app isn’t perfect example, lots opportunities precomputation caching ’ll willfully ignore today can better illustrate points want make async. ’re working app, though, please think carefully different techniques improving performance.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"converting-to-async","dir":"Articles","previous_headings":"","what":"Converting to async","title":"Case study: converting a Shiny app to async","text":"quote article Using promises Shiny, async programming Shiny boils following steps: Identify slow operations app. Convert slow operations mirai. code relies result operations (), whether directly indirectly, now must converted promise handlers operate mirai object. case, slow operations easy identify: downloading parsing takes place data reactive expression can take several long seconds. Converting download parsing operations mirai turns complicated part process, reasons ’ll get later. Assuming successfully, data reactive expression longer return data frame, promise object (resolves data frame). Since whales whale_downloads reactive expressions rely data, also need converted read return promise objects. therefore, outputs rely one reactive expressions, need know deal promise objects. Async code infectious like ; turn heart app promise, everything downstream must become promise-aware well, way observers outputs. overview way, let’s dive code. sections , ’ll take look code behind outputs reactive expressions. element, ’ll look first sync version, async version. cases, code snippets may slightly abridged. See GitHub repository full code. ’ve received introduction %...>% operator, async code make sense, haven’t read informal intro async programming /Working promises R, highly recommend continuing!","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"loading-promises-and-mirai","dir":"Articles","previous_headings":"Converting to async","what":"Loading promises and mirai","title":"Case study: converting a Shiny app to async","text":"first thing ’ll load basic libraries async programming. sets 6 daemons (background processes) local machine, also anything else supported daemons() function.","code":"library(promises) library(mirai) daemons(6)"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"the-data-reactive-mirai-all-the-things","dir":"Articles","previous_headings":"Converting to async","what":"The data reactive: mirai() all the things","title":"Case study: converting a Shiny app to async","text":"next thing ’ll convert data event reactive use mirai expensive bits. original code looks lke : (Earlier, said wouldn’t take advantage precomputation caching. wasn’t entirely true; code , cache log files download data_cache directory. couldn’t bring put internet connection level abuse, knew ’d running code thousands times load tested .) now, ’ll lose withProgress/setProgress reporting, since correctly requires advanced techniques ’ll talk later. ’ll come back fix code later, now: Pretty straightforward. reactive now returns mirai (counts promise), data frame. Remember must read reactive values (including input) reactive expressions outside mirai. (get error attempt read one inside mirai.) point, since long-running operations want make asynchronous, ’re actually done interacting directly mirai package. rest reactive expressions deal mirai returned data using general async functions operators promises.","code":"# SYNCHRONOUS version  data <- eventReactive(input$date, {   date <- input$date  # Example: 2018-05-28   year <- lubridate::year(date)  # Example: \"2018\"    url <- glue(\"http://cran-logs.rstudio.com/{year}/{date}.csv.gz\")   path <- file.path(\"data_cache\", paste0(date, \".csv.gz\"))    withProgress(value = NULL, {      if (!file.exists(path)) {       setProgress(message = \"Downloading data...\")       download.file(url, path)     }      setProgress(message = \"Parsing data...\")     read_csv(path, col_types = \"Dti---c-ci\", progress = FALSE)    }) }) # ASYNCHRONOUS version  data <- eventReactive(input$date, {   date <- input$date   year <- lubridate::year(date)    url <- glue(\"http://cran-logs.rstudio.com/{year}/{date}.csv.gz\")   path <- file.path(\"data_cache\", paste0(date, \".csv.gz\"))    mirai(     {       if (!file.exists(path)) {         download.file(url, path)       }       read_csv(path, col_types = \"Dti---c-ci\", progress = FALSE)     },     path = path,     url = url   ) })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"the-whales-reactive-simple-pipelines-are-simple","dir":"Articles","previous_headings":"Converting to async","what":"The whales reactive: simple pipelines are simple","title":"Case study: converting a Shiny app to async","text":"whales reactive takes data frame data, uses dplyr find top input$count prolific downloaders. Since data() now returns promise, whole function needs modified deal promises. basically best-case scenario working promises. whole expression consists single magrittr pipeline. ’s one object (data()) ’s converted promise. promise object appears , head pipeline. stars align like , converting code async literally easy replacing %>% %...>%: input (data()) promise, resulting output object promise, stage pipeline returns promise; can read write code almost easily synchronous version! example simple may seem reductive, best-case scenario happens surprisingly often, coding style influenced tidyverse. example app, 59% reactives, observers, outputs converted using nothing replacing %>% %...>%. One last thing move . last section, emphasized reactive values read inside mirai. , ’re using head(input$count) inside promise-pipeline; since data() written using mirai, doesn’t mean… well… isn’t wrong? Nope—code just fine. prohibition reading reactive values/expressions inside mirai, code inside mirai executed totally different R process. steps promise-pipeline mirai, promise handlers. aren’t executed different process; rather, ’re executed back original R process promise resolved. ’re allowed expected access reactive values expressions handlers.","code":"# SYNCHRONOUS version  whales <- reactive({   data() %>%     count(ip_id) %>%     arrange(desc(n)) %>%     head(input$count) }) # ASYNCHRONOUS version  whales <- reactive({   data() %...>%     count(ip_id) %...>%     arrange(desc(n)) %...>%     head(input$count) })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"the-whale_downloads-reactive-reading-from-multiple-promises","dir":"Articles","previous_headings":"Converting to async","what":"The whale_downloads reactive: reading from multiple promises","title":"Case study: converting a Shiny app to async","text":"whale_downloads reactive bit complicated case. Looks simple, can’t just simple replacement time. Can see ? Remember, data() whales() now return promise object, data frame. None dplyr verbs know deal promises natively (true almost every R function, anywhere R universe). ’re able use %...>% promises left-hand side regular dplyr calls right-hand side, %...>% operator “unwraps” promise object us, yielding regular object (data frame whatever) passed dplyr. case, ’re passing whales(), promise object, directly inner_join, inner_join idea . fundamental thing pattern-match , block code relies one promise object, means %...>% won’t enough. pretty common situation well, occurs 12% reactives outputs example app. ’s real solution looks like:","code":"# SYNCHRONOUS version  whale_downloads <- reactive({   data() %>%     inner_join(whales(), \"ip_id\") %>%     select(-n) }) # BAD VERSION DOESN'T WORK  whale_downloads <- reactive({   data() %...>%     inner_join(whales(), \"ip_id\") %...>%     select(-n) }) # ASYNCHRONOUS version  whale_downloads <- reactive({   promise_all(data_df = data(), whales_df = whales()) %...>% with({     data_df %>%       inner_join(whales_df, \"ip_id\") %>%       select(-n)   }) })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"promises-the-gathering","dir":"Articles","previous_headings":"Converting to async > The whale_downloads reactive: reading from multiple promises","what":"Promises: the Gathering","title":"Case study: converting a Shiny app to async","text":"solution uses promise gathering pattern, combines promises_all, %...>%, . promise_all function gathers multiple promise objects together, returns single promise object. new promise object doesn’t resolve input promise objects resolved, yields list results. %...>%, , “unwraps” promise object passes result right hand side. function (base R) takes named list, makes sort virtual parent environment evaluating code block pass . Let’s combine three, simplest possible example gathering pattern: can make use pattern without remembering exactly pieces combine. Just remember arguments promise_all provide promise objects (mirai(1) mirai(2)), along names want use refer yielded values (x y); code block put () can refer names without worrying fact ever promises begin .","code":"> promise_all(a = mirai(\"Hello\"), b = mirai(\"World\")) %...>% print() $a [1] \"Hello\"  $b [1] \"World\" > x + y Error: object 'x' not found  > with(list(x = 1, y = 2), { +   x + y + }) [1] 3 > promise_all(x = mirai(\"Hello\"), y = mirai(\"World\")) %...>% +   with({ paste(x, y) }) %...>% +   print() [1] \"Hello World\""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"the-total_downloaders-value-box-simple-pipelines-are-for-output-too","dir":"Articles","previous_headings":"Converting to async","what":"The total_downloaders value box: simple pipelines are for output, too","title":"Case study: converting a Shiny app to async","text":"value boxes app ended looking lot like : structurally different whales best-case scenario reactive. One thing worth pointing async renderValueBox means return promise returns valueBox; don’t return valueBox passed promise. Meaning, don’t : Instead, : trick worth nothing pull verb, used retrieve specific column data frame vector (similar $ [[). case, pull(data, ip_id) equivalent data[[\"ip_id\"]]. Note pull part dplyr isn’t specific promises.","code":"# SYNCHRONOUS version  output$total_downloaders <- renderValueBox({   data() %>%     pull(ip_id) %>%     unique() %>%     length() %>%     format(big.mark = \",\") %>%     valueBox(\"unique downloaders\") }) # BAD VERSION DOESN'T WORK  output$total_downloaders <- renderValueBox({   valueBox(     data() %...>%       pull(ip_id) %...>%       unique() %...>%       length() %...>%       format(big.mark = \",\"),     \"unique downloaders\"   ) }) # ASYNCHRONOUS version  output$total_downloaders <- renderValueBox({   data() %...>%     pull(ip_id) %...>%     unique() %...>%     length() %...>%     format(big.mark = \",\") %...>%     valueBox(\"unique downloaders\") })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"the-biggest_whales-plot-getting-untidy","dir":"Articles","previous_headings":"Converting to async","what":"The biggest_whales plot: getting untidy","title":"Case study: converting a Shiny app to async","text":"cruel twist API design fate, one cornerstone packages tidyverse lacks tidy API. ’m referring, course, ggplot2: dplyr tidyverse packages designed link calls together %>%, older ggplot2 package uses + operator. mostly small aesthetic wart synchronous code, ’s real problem async, promises package doesn’t currently promise-aware replacement + like %>%. Fortunately, ’s pretty good escape hatch %>%, %...>% inherited . Instead pipeline stage simple function call, can put { } delimited code block, inside code block, can access “” value using period (.). importance pattern overstated! Using %...>% simple calls alone, ’re restricted pipeline-compatible operations. %...>% together curly-brace code block means handler code can shape size. inside code block, regular, non-promise value . (even want use —sometimes don’t, ’ll see later). can zero, one, statements. can use . multiple times, nested expressions, whatever. Tip: extensive complex code put code block, start block creating properly named variable store value .. reason . may acquire different meaning intend add code code block. example, magrittr pipeline starts ., instead evaluating pipeline returning value, creates function takes single argument. following code wouldn’t filter resolved value whales(), instead, create anonymous function calls filter(n > 1000) whatever pass . fixes : ways work around problem well, like fix doesn’t require thought care. Just give . value new name, forget . exists. untidy code single promise object, just remember: pair single %...>% code block able almost anything.","code":"# SYNCHRONOUS version  output$downloaders <- renderPlot({   whales() %>%     ggplot(aes(ip_name, n)) +     geom_bar(stat = \"identity\") +     ylab(\"Downloads on this day\") }) # ASYNCHRONOUS version  output$downloaders <- renderPlot({   whales() %...>% {     whale_df <- .     ggplot(whale_df, aes(ip_name, n)) +       geom_bar(stat = \"identity\") +       ylab(\"Downloads on this day\")   } }) whales() %...>% {   . %>% filter(n > 1000) } whales() %...>% {   whales_df <- .   whales_df %>% filter(n > 1000) }"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"revisiting-the-data-reactive-progress-support","dir":"Articles","previous_headings":"Converting to async","what":"Revisiting the data reactive: progress support","title":"Case study: converting a Shiny app to async","text":"Now discussed techniques writing async code, let’s come back original data event reactive, time faithful async conversion preserves progress reporting functionality original. , ’s original sync code: Progress reporting currently presents two challenges mirai. First, withProgress({...}) function used async. withProgress designed wrap slow synchronous action, dismisses progress dialog block code wraps done executing. Since call mirai() return immediately even though actual task far done, using withProgress won’t work; progress dialog dismissed download even got going. ’s conceivable withProgress gain promise compatibility someday, ’s Shiny v1.1.0. meantime, can work around using alternative, object-oriented progress API Shiny offers. ’s bit verbose fiddly withProgress/setProgress, flexible enough work mirai/promises. Second, progress messages can’t sent mirai. simply mirai executed child processes, don’t direct access browser like main Shiny process . ’s conceivable mirai gain ability child processes communicate back parents, good solution exists time writing. meantime, can work around taking one mirai downloading parsing, splitting two separate mirai. download mirai completed, can send progress message parsing beginning, start parsing mirai. regrettably complicated solution . single mirai wrote earlier now become pipeline promises: mirai (download) send progress message mirai (parse) dismiss progress dialog Note neither R6 call p$set(message = ...) second mirai() call tidy, use curly-brace blocks, discussed section biggest_whales. final step dismissing progress dialog doesn’t use %...>% ; want progress dialog dismiss whether download parse operations succeed fail, use regular pipe %>% finally() function instead. See relevant section Working promises R learn . changes place, ’ve now covered changes application. can see full changes side--side via GitHub diff.","code":"# SYNCHRONOUS version  data <- eventReactive(input$date, {   date <- input$date  # Example: 2018-05-28   year <- lubridate::year(date)  # Example: \"2018\"    url <- glue(\"http://cran-logs.rstudio.com/{year}/{date}.csv.gz\")   path <- file.path(\"data_cache\", paste0(date, \".csv.gz\"))    withProgress(value = NULL, {      if (!file.exists(path)) {       setProgress(message = \"Downloading data...\")       download.file(url, path)     }      setProgress(message = \"Parsing data...\")     read_csv(path, col_types = \"Dti---c-ci\", progress = FALSE)    }) }) # ASYNCHRONOUS version  data <- eventReactive(input$date, {   date <- input$date   year <- lubridate::year(date)    url <- glue(\"http://cran-logs.rstudio.com/{year}/{date}.csv.gz\")   path <- file.path(\"data_cache\", paste0(date, \".csv.gz\"))    p <- Progress$new()   p$set(value = NULL, message = \"Downloading data...\")   mirai(     {       if (!file.exists(path)) {         download.file(url, path)       }     },     path = path,     url = url   ) %...>%     { p$set(message = \"Parsing data...\") } %...>%     { mirai(         {           read_csv(path, col_types = \"Dti---c-ci\", progress = FALSE)         },         path = path       ) } %>%     finally(~p$close()) })"},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"measuring-scalability","dir":"Articles","previous_headings":"","what":"Measuring scalability","title":"Case study: converting a Shiny app to async","text":"fair amount work sync--async conversion. Now ’d like know conversion async desired effect: improved responsiveness (.e. lower latency) number simultaneous visitors increases.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"load-testing-with-shiny-coming-soon","dir":"Articles","previous_headings":"Measuring scalability","what":"Load testing with Shiny (coming soon)","title":"Case study: converting a Shiny app to async","text":"time writing, working suite load testing tools Shiny publicly available yet, previewed Sean Lopp epic rstudio::conf 2018 talk running Shiny load test 10,000 simulated concurrent users. use tools easily record using Shiny app, creates test script; play back test script, multiplied dozens/hundreds/thousands simulated concurrent users; finally, analyze timing data generated playback step see kind latency simulated users experienced. examine effects async refactor, recorded simple test script loading app, waiting first tab appear, clicking tabs, pausing several seconds time moving next. using app without visitors, homepage fully loads less second, initial loading data rendering plot default tab takes 7 seconds. , tab takes couple seconds load. Overall, entire test script, including time user thinking, takes 40 seconds ideal settings (.e. single concurrent user). used test script generate load Shiny app running local RStudio. settings chose, playback tool introduced one new “user” session every 5 seconds, 50 sessions total launched; waited sessions complete. ran test sync async versions turn, generated following results.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"sync-vs--async-performance","dir":"Articles","previous_headings":"Measuring scalability","what":"Sync vs. async performance","title":"Case study: converting a Shiny app to async","text":"plot, row represents single session, x dimension represents time. rectangles represents single “step” test script, downloading HTML homepage, fetching one two dozen JavaScript/CSS files, waiting server update outputs. wider rectangle , longer user wait. (empty gaps rectangles represents time app waiting user click input; widths hard-coded test script.) particular importance red pink rectangles, represent initial page load. taking place, user staring blank page, probably wondering server . Long waits stage undesirable, surprising incomprehensible user; whereas user probably prepared wait little complicated visualization rendered response input change. can see plot, behavior async app much improved critical metric homepage/JS/CSS loading time. sync version app starts displaying unacceptably long red/pink loading times early session 15, session #44 maximum page load time exceeded one minute. async version point showing 25 second load times, far great, still significant step right direction.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"further-optimizations","dir":"Articles","previous_headings":"Measuring scalability","what":"Further optimizations","title":"Case study: converting a Shiny app to async","text":"surprised async version’s page load times weren’t even faster, even surprised see blue rectangles just wide sync version. isn’t async version way faster? sync version work single thread, specifically designed app nightmare scalability session kick parsing hundreds megabytes CSV, operation quite expensive. async version gets spread jobs across several workers. aren’t seeing greater time savings? Mostly, ’s calling mirai(read_csv(\"big_file.csv\")) almost worst-case scenario mirai async. read_csv generally fast, CRAN log files big, read_csv(\"big_file.csv\") slow. value returns large data frame, now loaded Shiny process, mirai daemon process. order return data frame Shiny process, data must first serialized, transmitted Shiny process, deserialized; make matters worse, transmitting deserialization steps happen main R thread ’re working hard try keep idle. larger data send back forth mirai, performance suffers, case ’re sending back quite lot data. can make code significantly faster summarizing, aggregation, filtering inside mirai; make work happen parallel, returning data already-processed form, can much less data transfer worker process back Shiny process. (example, data May 31, 2018 weighs 75MB optimization, 8.8MB afterwards.) Compare three runs image (newly optimized version labelled “async2”). homepage load times dropped , calculation times now dramatically faster sync code. Looking “async2” graph, leading (bottom-left) edge shape , ’s simply rate load testing tool launches new sessions. notice much closely trailing (upper-right) edge matches leading edge! means even number active sessions ramped , amount latency didn’t get dramatically worse, unlike “sync” “async” versions. individual blue rectangles “async2” comparatively tiny, meaning users never wait dozen seconds plots update. last plot shows data , sessions aligned start time. can clearly see sessions shorter less variable “async2” compared others. ’ve added yellow vertical line 10 second mark; page load (red/pink) completed point, ’s likely visitor left disgust. “async” better “sync”, break 10 second mark early often. contrast, “async2” version just barely peeks line three times. get visceral sense feels like use app load, ’s video shows ’s like browse app load test running peak. left side screen shows “sync”, right shows “async2”. cases, navigated app session #40 started.  Take look code diff async vs. async2. code changed dramatically, lost little elegance maintainability: code affected outputs now one foot render function one foot mirai. app’s total audience team hundred analysts execs, may choose forgo extra performance stick original async (even sync) code. serious scaling needs, refactoring probably small price pay. Let’s get real second, though. weren’t example app written exposition purposes, real production app intended scale thousands concurrent users across dozens R processes, wouldn’t download parse CSV files fly. Instead, ’d establish proper ETL procedure run every night put results properly indexed database table, RDS files just data need. said earlier, little precomputation caching can make huge difference! Much remaining latency async2 branch ggplot2 plotting. Sean’s talk alluded upcoming plot caching features ’re adding Shiny, imagine dramatic effect test Sean.","code":""},{"path":"https://rstudio.github.io/promises/dev/articles/promises_08_casestudy.html","id":"summing-up","dir":"Articles","previous_headings":"","what":"Summing up","title":"Case study: converting a Shiny app to async","text":"async programming, expensive computations tasks longer need scalability killers Shiny. Armed common techniques like precomputation, caching, load balancing, ’s possible write responsive scalable Shiny applications can safely deployed thousands concurrent users.","code":""},{"path":"https://rstudio.github.io/promises/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Joe Cheng. Author, maintainer. Barret Schloerke. Author. Winston Chang. Author. . Copyright holder, funder.","code":""},{"path":"https://rstudio.github.io/promises/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Cheng J, Schloerke B, Chang W (2025). promises: Abstractions Promise-Based Asynchronous Programming. R package version 1.3.3.9000, https://rstudio.github.io/promises/.","code":"@Manual{,   title = {promises: Abstractions for Promise-Based Asynchronous Programming},   author = {Joe Cheng and Barret Schloerke and Winston Chang},   year = {2025},   note = {R package version 1.3.3.9000},   url = {https://rstudio.github.io/promises/}, }"},{"path":"https://rstudio.github.io/promises/dev/index.html","id":"promises","dir":"","previous_headings":"","what":"Abstractions for Promise-Based Asynchronous Programming","title":"Abstractions for Promise-Based Asynchronous Programming","text":"promises package brings asynchronous programming capabilities R. Asynchronous programming technique used many programming languages increase scalability responsiveness. Traditionally, style programming useful R users. advent R web applications like Shiny made async programming relevant. website provides multi-step guide help familiarize several related concepts required effective async programming. highly recommended go topics order.","code":""},{"path":"https://rstudio.github.io/promises/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Abstractions for Promise-Based Asynchronous Programming","text":"","code":"install.packages(\"promises\")"},{"path":[]},{"path":[]},{"path":"https://rstudio.github.io/promises/dev/index.html","id":"id_1-why-use-promises","dir":"","previous_headings":"Contents > Overview","what":"1. Why use promises?","title":"Abstractions for Promise-Based Asynchronous Programming","text":"need async programming? good , good ?","code":""},{"path":"https://rstudio.github.io/promises/dev/index.html","id":"id_2-an-informal-intro-to-async-programming","dir":"","previous_headings":"Contents > Overview","what":"2. An informal intro to async programming","title":"Abstractions for Promise-Based Asynchronous Programming","text":"Async programming can require serious mental shift, even veteran programmers. document attempts introduce “average” R user topic, gently possible.","code":""},{"path":"https://rstudio.github.io/promises/dev/index.html","id":"id_3-working-with-promises","dir":"","previous_headings":"Contents > Overview","what":"3. Working with promises","title":"Abstractions for Promise-Based Asynchronous Programming","text":"thorough exploration concepts behind promises, API provided promises package.","code":""},{"path":[]},{"path":"https://rstudio.github.io/promises/dev/index.html","id":"id_4-launching-tasks","dir":"","previous_headings":"Contents > Integration","what":"4. Launching tasks","title":"Abstractions for Promise-Based Asynchronous Programming","text":"guide mirai package, place expect async programming R begin.","code":""},{"path":"https://rstudio.github.io/promises/dev/index.html","id":"id_5a-launching-tasks-with-future","dir":"","previous_headings":"Contents > Integration","what":"5a. Launching tasks with future","title":"Abstractions for Promise-Based Asynchronous Programming","text":"guide future package, alternative async programming R package pre-dates mirai.","code":""},{"path":"https://rstudio.github.io/promises/dev/index.html","id":"id_5b-advance-future-and-promises-usage","dir":"","previous_headings":"Contents > Integration","what":"5b. Advance future and promises usage","title":"Abstractions for Promise-Based Asynchronous Programming","text":"Leverage promises make sure future execution block main R process.","code":""},{"path":[]},{"path":"https://rstudio.github.io/promises/dev/index.html","id":"id_6-using-promises-with-shiny","dir":"","previous_headings":"Contents > Usage","what":"6. Using promises with Shiny","title":"Abstractions for Promise-Based Asynchronous Programming","text":"Learn integrate promises Shiny applications.","code":""},{"path":"https://rstudio.github.io/promises/dev/index.html","id":"id_7-combining-promises","dir":"","previous_headings":"Contents > Usage","what":"7. Combining promises","title":"Abstractions for Promise-Based Asynchronous Programming","text":"Functions techniques working multiple promises simultaneously.","code":""},{"path":"https://rstudio.github.io/promises/dev/index.html","id":"id_8-case-study-converting-a-shiny-app-to-async","dir":"","previous_headings":"Contents > Usage","what":"8. Case study: converting a Shiny app to async","title":"Abstractions for Promise-Based Asynchronous Programming","text":"Walk conversion realistic Shiny example app async.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/WorkQueue.html","id":null,"dir":"Reference","previous_headings":"","what":"Future promise work queue — WorkQueue","title":"Future promise work queue — WorkQueue","text":"Future promise work queue Future promise work queue","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/WorkQueue.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Future promise work queue — WorkQueue","text":"#' R6 class help scheduling work completed. WorkQueue execute work can_proceed() returns TRUE. use case future, can_proceed() defaults future::nbrOfFreeWorkers() > 0 allow work executed future worker available. WorkQueue constantly try start new work prior work item finishes.  However, can_proceed() returns FALSE (future workers available) work done, work attempted later random amount time later using exponential backoff.  exponential backoff cap 10 seconds prevent unnecessarily large wait times. time WorkQueue tries start work, repeat can_proceed() returns FALSE work queue.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/WorkQueue.html","id":"global-event-loop","dir":"Reference","previous_headings":"","what":"Global event loop","title":"Future promise work queue — WorkQueue","text":"global loop used default internal WorkQueue \"delayed check\" uses single delay check whole queue, rather item queue attempt process. behavior might change future, exactly sure point. private later loop wants become synchronous running jobs completed waiting future_promise(), private loop complete unless global loop allowed move forward. However, possible use private loop inside user-defined WorkQueue may work can provided directly future_promise(queue=custom_queue). concrete example (need) help us understand problem better. example, please reach .","code":""},{"path":[]},{"path":[]},{"path":"https://rstudio.github.io/promises/dev/reference/WorkQueue.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Future promise work queue — WorkQueue","text":"WorkQueue$new() WorkQueue$schedule_work() WorkQueue$clone()","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/WorkQueue.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Future promise work queue — WorkQueue","text":"Create new WorkQueue","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/WorkQueue.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Future promise work queue — WorkQueue","text":"","code":"WorkQueue$new(   can_proceed = future_worker_is_free,   queue = fastmap::fastqueue(),   loop = later::global_loop() )"},{"path":"https://rstudio.github.io/promises/dev/reference/WorkQueue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Future promise work queue — WorkQueue","text":"can_proceed Function return logical value. TRUE returned, next scheduled work executed. default, function checks future::nbrOfFreeWorkers() > 0 queue Queue object use store scheduled work. default, \"First , First \" queue using fastmap::fastqueue(). using queue, methods $add(x), $remove(), $size(). loop later loop use calculating next delayed check. Defaults later::global_loop(). Schedule work","code":""},{"path":[]},{"path":"https://rstudio.github.io/promises/dev/reference/WorkQueue.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Future promise work queue — WorkQueue","text":"","code":"WorkQueue$schedule_work(fn)"},{"path":"https://rstudio.github.io/promises/dev/reference/WorkQueue.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Future promise work queue — WorkQueue","text":"fn function execute can_proceed() returns TRUE.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/WorkQueue.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Future promise work queue — WorkQueue","text":"objects class cloneable method.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/WorkQueue.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Future promise work queue — WorkQueue","text":"","code":"WorkQueue$clone(deep = FALSE)"},{"path":"https://rstudio.github.io/promises/dev/reference/WorkQueue.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Future promise work queue — WorkQueue","text":"deep Whether make deep clone.","code":""},{"path":[]},{"path":"https://rstudio.github.io/promises/dev/reference/future_promise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"future promise — future_promise_queue","text":"","code":"future_promise_queue()  future_promise(   expr = NULL,   envir = parent.frame(),   ...,   substitute = TRUE,   queue = future_promise_queue() )"},{"path":"https://rstudio.github.io/promises/dev/reference/future_promise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"future promise — future_promise_queue","text":"expr R expression. expr eventually sent future::future(), please use precautions use regular promises::promise() expressions. future_promise() may hold expr promise() waiting future worker become available. envir environment global objects identified. ... extra parameters provided future::future() substitute TRUE, argument expr substitute():ed, otherwise . queue queue used schedule work done using future::future().  queue defaults future_promise_queue() requires method queue$schedule_work(fn) exist.  method take function execute promised future work.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/future_promise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"future promise — future_promise_queue","text":"Unlike future::future(), future_promise() returns promise() object eventually resolve future expr.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/future_promise.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"future promise — future_promise_queue","text":"submitting future work, future (design) block main R session worker becomes available. occurs submitted future work available future workers. counter situation, can create promise execute work using future (using future_promise()) begin work future worker available. Using future_promise() recommended whenever continuous runtime used, plumber shiny. details examples, please see vignette(\"future_promise\", \"promises\") vignette.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/future_promise.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"future promise — future_promise_queue","text":"future_promise_queue(): Default future_promise() work queue use. function returns WorkQueue cached per R session. future_promise(): Creates promise() execute expr using future::future().","code":""},{"path":[]},{"path":"https://rstudio.github.io/promises/dev/reference/future_promise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"future promise — future_promise_queue","text":"","code":"if (FALSE) # Relative start time start <- Sys.time() # Helper to force two `future` workers with_two_workers <- function(expr) {   if (!require(\"future\")) {     message(\"`future` not installed\")     return()   }   old_plan <- future::plan(future::multisession, workers = 2)   on.exit({future::plan(old_plan)}, add = TRUE)   start <<- Sys.time()   force(expr)   while(!later::loop_empty()) {Sys.sleep(0.1); later::run_now()}   invisible() } # Print a status message. Ex: `\"PID: XXX; 2.5s promise done\"` print_msg <- function(pid, msg) {   message(     \"PID: \", pid, \"; \",     round(difftime(Sys.time(), start, units = \"secs\"), digits = 1), \"s \" ,     msg   ) }  # `\"promise done\"` will appear after four workers are done and the main R session is not blocked # The important thing to note is the first four times will be roughly the same with_two_workers({   promise_resolve(Sys.getpid()) %...>% print_msg(\"promise done\")   for (i in 1:6) future::future({Sys.sleep(1); Sys.getpid()}) %...>% print_msg(\"future done\") }) #> Loading required package: future #> Error in with_two_workers({    promise_resolve(Sys.getpid()) %...>% print_msg(\"promise done\")    for (i in 1:6) future::future({        Sys.sleep(1)        Sys.getpid()    }) %...>% print_msg(\"future done\")}): cannot change value of locked binding for 'start' { #> PID: XXX; 2.5s promise done #> PID: YYY; 2.6s future done #> PID: ZZZ; 2.6s future done #> PID: YYY; 2.6s future done #> PID: ZZZ; 2.6s future done #> PID: YYY; 3.4s future done #> PID: ZZZ; 3.6s future done } #> NULL  # `\"promise done\"` will almost immediately, before any workers have completed # The first two `\"future done\"` comments appear earlier the example above with_two_workers({   promise_resolve(Sys.getpid()) %...>% print_msg(\"promise\")   for (i in 1:6) future_promise({Sys.sleep(1); Sys.getpid()}) %...>% print_msg(\"future done\") }) #> Error in start <<- Sys.time(): cannot change value of locked binding for 'start' { #> PID: XXX; 0.2s promise done #> PID: YYY; 1.3s future done #> PID: ZZZ; 1.4s future done #> PID: YYY; 2.5s future done #> PID: ZZZ; 2.6s future done #> PID: YYY; 3.4s future done #> PID: ZZZ; 3.6s future done } # \\dontrun{} #> NULL"},{"path":"https://rstudio.github.io/promises/dev/reference/is.promise.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce to a promise — is.promise","title":"Coerce to a promise — is.promise","text":"Use .promise determine whether R object promise. Use .promise (S3 generic method) attempt coerce R object promise, .promising (another S3 generic method) test whether .promise supported. mirai::mirai objects .promise method defined mirai package, package provides one converting future::Future objects promises.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/is.promise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce to a promise — is.promise","text":"","code":"is.promise(x)  is.promising(x)  as.promise(x)"},{"path":"https://rstudio.github.io/promises/dev/reference/is.promise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce to a promise — is.promise","text":"x R object test coerce.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/is.promise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce to a promise — is.promise","text":".promise returns promise object, throws error object converted. .promise returns TRUE given value promise object, FALSE otherwise. .promising returns TRUE given value promise object can converted promise object using .promise, FALSE otherwise.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/pipes.html","id":null,"dir":"Reference","previous_headings":"","what":"Promise pipe operators — pipes","title":"Promise pipe operators — pipes","text":"Promise-aware pipe operators, style magrittr. Like magrittr pipes, operators can used chain together pipelines promise-transforming operations. Unlike magrittr pipes, pipes wait promise resolution pass unwrapped value (error) rhs function call.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/pipes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Promise pipe operators — pipes","text":"","code":"lhs %...>% rhs  lhs %...T>% rhs  lhs %...!% rhs  lhs %...T!% rhs"},{"path":"https://rstudio.github.io/promises/dev/reference/pipes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Promise pipe operators — pipes","text":"lhs promise object. rhs function call using magrittr semantics. can return either promise non-promise value, throw error.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/pipes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Promise pipe operators — pipes","text":"new promise.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/pipes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Promise pipe operators — pipes","text":"> variants handling successful resolution, ! variants handling errors. T variants return lhs instead rhs, useful pipeline steps used side effects (printing, plotting, saving). promise %...>% func() equivalent promise %>% (func). promise %...!% func() equivalent promise %>% catch(func). promise %...T>% func() equivalent promise %T>% (func). promise %...T!% func() equivalent promise %T>% catch(func) promise %>% catch(func, tee = TRUE). One situation 3. 4. break func() throws error, returns promise ultimately fails. case, failure propagated pipe operators magrittr-plus-function \"equivalents\". simplicity implementation, support magrittr feature using . head pipeline turn entire pipeline function instead expression.","code":""},{"path":[]},{"path":"https://rstudio.github.io/promises/dev/reference/pipes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Promise pipe operators — pipes","text":"","code":"if (FALSE) { # \\dontrun{ library(mirai)  mirai(cars) %...>%   head(5) %...T>%   print()  # If the read.csv fails, resolve to NULL instead mirai(read.csv(\"http://example.com/data.csv\")) %...!%   { NULL } } # }"},{"path":"https://rstudio.github.io/promises/dev/reference/promise.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new promise object — promise","title":"Create a new promise object — promise","text":"promise() creates new promise. promise placeholder object eventual result (error) asynchronous operation. function generally needed carry asynchronous programming tasks; instead, intended used mostly package authors want write asynchronous functions return promises.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new promise object — promise","text":"","code":"promise(action)"},{"path":"https://rstudio.github.io/promises/dev/reference/promise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new promise object — promise","text":"action function signature function(resolve, reject), one-sided formula. See Details.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new promise object — promise","text":"promise object (see ).","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a new promise object — promise","text":"action function piece code returns quickly, initiates potentially long-running, asynchronous task. /task successfully completes, call resolve(value) value result computation (like return value). task fails, call reject(reason), reason either error object, character string. important asynchronous tasks kicked action coded carefully–particular, errors must caught passed reject(). Failure cause errors lost, best; caller asynchronous task never receive response (asynchronous equivalent function call never returns, .e. hangs). return value action ignored.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new promise object — promise","text":"","code":"# Create a promise that resolves to a random value after 2 secs p1 <- promise(function(resolve, reject) {   later::later(~resolve(runif(1)), delay = 2) })  p1 %...>% print()  # Create a promise that errors immediately p2 <- promise(~{   reject(\"An error has occurred\") }) then(p2,   onFulfilled = ~message(\"Success\"),   onRejected = ~message(\"Failure\") )"},{"path":"https://rstudio.github.io/promises/dev/reference/promise_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine multiple promise objects — promise_all","title":"Combine multiple promise objects — promise_all","text":"Use promise_all wait multiple promise objects successfully fulfilled. Use promise_race wait first multiple promise objects either fulfilled rejected.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine multiple promise objects — promise_all","text":"","code":"promise_all(..., .list = NULL)  promise_race(..., .list = NULL)"},{"path":"https://rstudio.github.io/promises/dev/reference/promise_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine multiple promise objects — promise_all","text":"... Promise objects. Either arguments must named, arguments must unnamed. .list provided, arguments ignored. .list list promise objects–alternative ....","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise_all.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine multiple promise objects — promise_all","text":"promise. promise_all, promises successful, returned promise resolve list promises' values; promise fails, first error encountered used reject returned promise. promise_race, first promises either fulfill reject passed returned promise.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise_all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine multiple promise objects — promise_all","text":"","code":"p1 <- promise(~later::later(~resolve(1), delay = 1)) p2 <- promise(~later::later(~resolve(2), delay = 2))  # Resolves after 1 second, to the value: 1 promise_race(p1, p2) %...>% {   cat(\"promise_race:\\n\")   str(.) }  # Resolves after 2 seconds, to the value: list(1, 2) promise_all(p1, p2) %...>% {   cat(\"promise_all:\\n\")   str(.) }"},{"path":"https://rstudio.github.io/promises/dev/reference/promise_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Promise-aware lapply/map — promise_map","title":"Promise-aware lapply/map — promise_map","text":"Similar base::lapply() purrr::map, promise-aware: .f function permitted return promises, lapply returns list, promise_map returns promise resolves similar list (resolved values , promises).","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Promise-aware lapply/map — promise_map","text":"","code":"promise_map(.x, .f, ...)"},{"path":"https://rstudio.github.io/promises/dev/reference/promise_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Promise-aware lapply/map — promise_map","text":".x vector (atomic list) expression object (promise). objects (including classed objects) coerced base::.list. .f function applied element .x. function permitted, required, return promise. ... Optional arguments .f.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Promise-aware lapply/map — promise_map","text":"promise resolves list (values, promises).","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise_map.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Promise-aware lapply/map — promise_map","text":"promise_map processes elements .x serially; , .f(.x[[1]]) returns promise, .f(.x[[2]]) invoked promise resolved. promise rejects (errors), promise returned promise_map immediately rejects err.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Promise-aware lapply/map — promise_map","text":"","code":"# Waits x seconds, then returns x*10 wait_this_long <- function(x) {   promise(~later::later(~{     resolve(x*10)   }, delay = x)) }  promise_map(list(A=1, B=2, C=3), wait_this_long) %...>%   print()"},{"path":"https://rstudio.github.io/promises/dev/reference/promise_reduce.html","id":null,"dir":"Reference","previous_headings":"","what":"Promise-aware version of Reduce — promise_reduce","title":"Promise-aware version of Reduce — promise_reduce","text":"Similar purrr::reduce (left fold), function .f permitted return promise. promise_reduce wait returned promise resolve invoking .f next element; words, execution serial. .f can return promise output never encounter promise input (unless .x list promises begin , case second parameter promise).","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise_reduce.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Promise-aware version of Reduce — promise_reduce","text":"","code":"promise_reduce(.x, .f, ..., .init)"},{"path":"https://rstudio.github.io/promises/dev/reference/promise_reduce.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Promise-aware version of Reduce — promise_reduce","text":".x vector list reduce. (promise.) .f function takes two parameters. first parameter \"result\" (initially .init, set result recent call func), second parameter element .x. ... arguments pass .f .init initial result value fold, passed .f first executed.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise_reduce.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Promise-aware version of Reduce — promise_reduce","text":"promise resolve result calling .f last element (.init .x elements). invocation .f results error rejected promise, overall promise_reduce promise immediately reject error.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise_reduce.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Promise-aware version of Reduce — promise_reduce","text":"","code":"# Returns a promise for the sum of e1 + e2, with a 0.5 sec delay slowly_add <- function(e1, e2) {   promise(~later::later(~resolve(e1 + e2), delay = 0.5)) }  # Prints 55 after a little over 5 seconds promise_reduce(1:10, slowly_add, .init = 0) %...>% print()"},{"path":"https://rstudio.github.io/promises/dev/reference/promise_resolve.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a resolved or rejected promise — promise_resolve","title":"Create a resolved or rejected promise — promise_resolve","text":"Helper functions conveniently create promise resolved given value (rejected given reason).","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise_resolve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a resolved or rejected promise — promise_resolve","text":"","code":"promise_resolve(value)  promise_reject(reason)"},{"path":"https://rstudio.github.io/promises/dev/reference/promise_resolve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a resolved or rejected promise — promise_resolve","text":"value value, promise, new promise resolved . expression lazily evaluated, evaluating expression raises error, new promise rejected error reason. reason error message string, error object.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/promise_resolve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a resolved or rejected promise — promise_resolve","text":"","code":"promise_resolve(mtcars) %...>%   head() %...>%   print()  promise_reject(\"Something went wrong\") %...T!%   { message(conditionMessage(.)) }"},{"path":"https://rstudio.github.io/promises/dev/reference/promises-package.html","id":null,"dir":"Reference","previous_headings":"","what":"promises: Abstractions for Promise-Based Asynchronous Programming — promises-package","title":"promises: Abstractions for Promise-Based Asynchronous Programming — promises-package","text":"Provides fundamental abstractions asynchronous programming R using promises. Asynchronous programming useful allowing single R process orchestrate multiple tasks background also attending something else. Semantics similar 'JavaScript' promises, syntax idiomatic R.","code":""},{"path":[]},{"path":"https://rstudio.github.io/promises/dev/reference/promises-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"promises: Abstractions for Promise-Based Asynchronous Programming — promises-package","text":"Maintainer: Joe Cheng joe@posit.co Authors: Barret Schloerke barret@posit.co (ORCID) Winston Chang winston@posit.co (ORCID) contributors: Posit Software, PBC (03wc8by49) [copyright holder, funder]","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. magrittr %>%, %T>%","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/resolve.html","id":null,"dir":"Reference","previous_headings":"","what":"Fulfill a promise — resolve","title":"Fulfill a promise — resolve","text":"Use functions satisfy promise either success (resolve) failure (reject). functions exported, rather, passed arguments action function pass promise constructor.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/resolve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fulfill a promise — resolve","text":"","code":"resolve(value = NULL)  reject(reason)"},{"path":"https://rstudio.github.io/promises/dev/reference/resolve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fulfill a promise — resolve","text":"value result successful calculation. reason error string explains operation failed.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/then.html","id":null,"dir":"Reference","previous_headings":"","what":"Access the results of a promise — then","title":"Access the results of a promise — then","text":"Use function access eventual result promise (, operation fails, reason failure). Regardless state promise, call non-blocking, , returns immediately; immediately return result value promise. Instead, pass logic want execute , form function callbacks (formulas, see Details). provide onFulfilled callback, called upon promise's successful resolution, single argument value: result value. provide onRejected callback, called operation fails, single argument reason: error caused failure.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/then.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access the results of a promise — then","text":"","code":"then(promise, onFulfilled = NULL, onRejected = NULL)  catch(promise, onRejected, tee = FALSE)  finally(promise, onFinally)"},{"path":"https://rstudio.github.io/promises/dev/reference/then.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Access the results of a promise — then","text":"promise promise object. object can state. onFulfilled function (formula–see Details) invoked promise value successfully resolves. invoked, function called single argument: resolved value. Optionally, function can take second parameter .visible care whether promise resolved visible invisible value. function can return value promise object, can throw error; affect resolution promise object returned (). onRejected function taking argument error (formula–see Details). function can return value promise object, can throw error. onRejected provided throw error (return promise fails) async equivalent catching error. tee TRUE, ignore return value callback, use original value instead. useful performing operations side-effects, particularly logging console file. callback throws error, tee TRUE, error still used fulfill returned promise (words, tee effect callback throw). onFinally function arguments, called async operation either succeeds fails. Usually used freeing resources used async operations.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/then.html","id":"formulas","dir":"Reference","previous_headings":"","what":"Formulas","title":"Access the results of a promise — then","text":"convenience, (), catch(), finally() functions use rlang::as_function() convert onFulfilled, onRejected, onFinally arguments functions. means can use formulas create compact anonymous functions, using . access value (case onFulfilled) error (case onRejected).","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/then.html","id":"chaining-promises","dir":"Reference","previous_headings":"","what":"Chaining promises","title":"Access the results of a promise — then","text":"first parameter promise; given stated purpose function, surprise. However, may surprising return value also (newly created) promise. new promise waits original promise fulfilled rejected, onFulfilled onRejected called. result (error raised ) calling onFulfilled/onRejected used fulfill (reject) new promise.   example, assuming get_data_frame_async returns promise eventually resolves data frame, promise_b eventually resolve first 10 fewer rows data frame. Note new promise considered fulfilled rejected based whether onFulfilled/onRejected returns value throws error, whether original promise fulfilled rejected. words, possible turn failure success success failure. Consider example, expect some_async_operation fail, want consider error :   Now, promise_d rejected promise_c fulfilled, vice versa. Warning: careful accidentally turn failure success, error handling code last item chain!   example, catch callback throw error, subsequent call consider promise fulfilled!","code":"promise_a <- get_data_frame_async() promise_b <- then(promise_a, onFulfilled = head) promise_c <- some_async_operation() promise_d <- then(promise_c,   onFulfilled = function(value) {     stop(\"That's strange, the operation didn't fail!\")   },   onRejected = function(reason) {     # Great, the operation failed as expected     NULL   } ) some_async_operation() %>%   catch(function(reason) {     warning(\"An error occurred: \", reason)   }) %>%   then(function() {     message(\"I guess we succeeded...?\")  # No!   })"},{"path":"https://rstudio.github.io/promises/dev/reference/then.html","id":"convenience-functions","dir":"Reference","previous_headings":"","what":"Convenience functions","title":"Access the results of a promise — then","text":"readability convenience, provide catch finally functions. catch function equivalent , without onFulfilled argument. typically used end promise chain perform error handling/logging. finally function similar , takes single -argument function (formula) executed upon completion promise, regardless whether result success failure. typically used end promise chain perform cleanup tasks, like closing file handles database connections. Unlike catch, return value finally ignored; however, error thrown finally, error propagated forward returned promise.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/then.html","id":"visibility","dir":"Reference","previous_headings":"","what":"Visibility","title":"Access the results of a promise — then","text":"onFulfilled functions can optionally second parameter visible, FALSE result value invisible.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/with_promise_domain.html","id":null,"dir":"Reference","previous_headings":"","what":"Promise domains — with_promise_domain","title":"Promise domains — with_promise_domain","text":"Promise domains used temporarily set custom environments intercept influence registration callbacks. Create new promise domain objects using new_promise_domain, temporarily activate promise domain object (duration evaluating given expression) using with_promise_domain.","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/with_promise_domain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Promise domains — with_promise_domain","text":"","code":"with_promise_domain(domain, expr, replace = FALSE)  new_promise_domain(   wrapOnFulfilled = identity,   wrapOnRejected = identity,   wrapSync = force,   onError = force,   ...,   wrapOnFinally = NULL )"},{"path":"https://rstudio.github.io/promises/dev/reference/with_promise_domain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Promise domains — with_promise_domain","text":"domain promise domain object install expr evaluated. expr R expression, evaluated influence domain. replace FALSE, effect domain added effect currently active promise domain(s). TRUE, current promise domain(s) ignored duration with_promise_domain call. wrapOnFulfilled function takes single argument: function passed onFulfilled argument (). wrapOnFulfilled function return function suitable onFulfilled duty. wrapOnRejected function takes single argument: function passed onRejected argument (). wrapOnRejected function return function suitable onRejected duty. wrapSync function takes single argument: (lazily evaluated) expression function force(). expression represents expr argument passed with_promise_domain(); wrapSync allows domain manipulate environment /expr evaluated. onError function takes single argument: error. onError called whenever exception occurs domain (caught tryCatch). Providing onError callback cause errors caught, necessarily; instead, onError callbacks behave like calling handlers. ... Arbitrary named values become elements promise domain object, can accessed items environment (.e. using [[ $). wrapOnFinally function takes single argument: function passed onFinally argument (). wrapOnFinally function return function suitable onFinally duty. wrapOnFinally NULL (default), domain use wrapOnFulfilled wrapOnRejected wrap onFinally. important distinguish normal fulfillment/rejection handlers finally handlers, sure provide wrapOnFinally, even just base::identity().","code":""},{"path":"https://rstudio.github.io/promises/dev/reference/with_promise_domain.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Promise domains — with_promise_domain","text":"with_promise_domain call stack, calls () (higher level functions operators, like catch() various pipes) belong promise domain. addition, callback belongs promise domain invoked, new calls also belong promise domain. words, promise domain \"infects\" immediate calls , also \"nested\" calls . background, read original design doc. examples, see source code Shiny package, uses promise domains extensively manage graphics devices reactivity.","code":""},{"path":"https://rstudio.github.io/promises/dev/news/index.html","id":"promises-development-version","dir":"Changelog","previous_headings":"","what":"promises (development version)","title":"promises (development version)","text":"Fixed #47: promise_map() can now properly handle NULL values returned. (Thank , @RLesur! #138)","code":""},{"path":"https://rstudio.github.io/promises/dev/news/index.html","id":"promises-133","dir":"Changelog","previous_headings":"","what":"promises 1.3.3","title":"promises 1.3.3","text":"CRAN release: 2025-05-29 Changed way create future objects stay compatible new versions future. Apparently way never idiomatic worked accident. (#121) Fixed #122: Use future::future(..., lazy = TRUE) avoid manual capturing state within future_promise (Thank , @HenrikBengtsson! #123)","code":""},{"path":"https://rstudio.github.io/promises/dev/news/index.html","id":"promises-132","dir":"Changelog","previous_headings":"","what":"promises 1.3.2","title":"promises 1.3.2","text":"CRAN release: 2024-11-27 Fixed bug introduced 1.3.1, promise domains active promise resolution time stay active handler callback, even weren’t active handler registered. causing stack overflow long promise chains many active promise domains. (#115)","code":""},{"path":"https://rstudio.github.io/promises/dev/news/index.html","id":"promises-131","dir":"Changelog","previous_headings":"","what":"promises 1.3.1","title":"promises 1.3.1","text":"CRAN release: 2024-11-26 Fixed bug promise domains forgotten handlers registered within handlers. (#110)","code":""},{"path":"https://rstudio.github.io/promises/dev/news/index.html","id":"promises-130","dir":"Changelog","previous_headings":"","what":"promises 1.3.0","title":"promises 1.3.0","text":"CRAN release: 2024-04-05 .promising now S3 method. (#104)","code":""},{"path":"https://rstudio.github.io/promises/dev/news/index.html","id":"promises-121","dir":"Changelog","previous_headings":"","what":"promises 1.2.1","title":"promises 1.2.1","text":"CRAN release: 2023-08-10 future_promise() received speed improvement submitting many requests minimal number future workers. future_promise() runs available future workers, future_promise() preemptively return remainder current later execution. possible future finish job submitting future_promise() requests, time saved asking future’s worker availability faster overall jobs submitted early. (#78) Fixed #86: future_promise() spuriously reports unhandled errors. (#90) Move fastmap Suggests Imports better renv discovery. (#87)","code":""},{"path":"https://rstudio.github.io/promises/dev/news/index.html","id":"promises-1201","dir":"Changelog","previous_headings":"","what":"promises 1.2.0.1","title":"promises 1.2.0.1","text":"CRAN release: 2021-02-11 Added future_promise() returns promise executes expression using future::future(). future_promise() (typically) drop-replacement future::future() function call. future_promise() execute future work faster future::future(), future_promise() submit future jobs worker available. workers available, future_promise() hold expression information promise worker become available better take advantage computing resources available main R session. information, please see future_promise() article. (#62) Added visibility support Promise$(onFulfilled). (#59)","code":""},{"path":"https://rstudio.github.io/promises/dev/news/index.html","id":"promises-111","dir":"Changelog","previous_headings":"","what":"promises 1.1.1","title":"promises 1.1.1","text":"CRAN release: 2020-06-09 Fix handling FutureErrors future::resolved() future::value() discarding corrupt future. (#37)","code":""},{"path":"https://rstudio.github.io/promises/dev/news/index.html","id":"promises-110","dir":"Changelog","previous_headings":"","what":"promises 1.1.0","title":"promises 1.1.0","text":"CRAN release: 2019-10-04 Fixed #49: promise_all() previously handle NULL values correctly. (#50)) new_promise_domain now takes wrapOnFinally argument, can used intercept registration finally(). Previous versions treated finally passing callback (onFulfilled=..., onRejected=...), ignoring result; backward compatibility, promise domains still treat finally way default (.e. wrapOnFinally NULL, finally result wrapOnFulfilled wrapOnRejected called, wrapOnFinally provided wrapOnFinally called). (#43)","code":""},{"path":"https://rstudio.github.io/promises/dev/news/index.html","id":"promises-101","dir":"Changelog","previous_headings":"","what":"promises 1.0.1","title":"promises 1.0.1","text":"CRAN release: 2018-04-13 Initial CRAN release","code":""}]
